{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"adam class.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cJDHLu3GeHWU","executionInfo":{"status":"ok","timestamp":1656242788044,"user_tz":-330,"elapsed":3425,"user":{"displayName":"Prudhvi Vuda","userId":"08510694787031450796"}},"outputId":"80809011-9b01-4c85-e627-4b0b1defed60"},"execution_count":528,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"nn_DPtIbq7ru","executionInfo":{"status":"ok","timestamp":1656242788044,"user_tz":-330,"elapsed":19,"user":{"displayName":"Prudhvi Vuda","userId":"08510694787031450796"}}},"source":["import tensorflow as tf\n","from tensorflow import keras\n","# from tensorflow.keras import layers\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import keras\n","np.random.seed(1337)"],"execution_count":529,"outputs":[]},{"cell_type":"code","metadata":{"id":"nockS_3Jq8ve","executionInfo":{"status":"ok","timestamp":1656242788045,"user_tz":-330,"elapsed":19,"user":{"displayName":"Prudhvi Vuda","userId":"08510694787031450796"}}},"source":["import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","from pandas.plotting import scatter_matrix\n","from sklearn.metrics import classification_report"],"execution_count":530,"outputs":[]},{"cell_type":"code","metadata":{"id":"UR7AiwC_rIyK","executionInfo":{"status":"ok","timestamp":1656242788045,"user_tz":-330,"elapsed":17,"user":{"displayName":"Prudhvi Vuda","userId":"08510694787031450796"}}},"source":["df=pd.read_csv(\"/content/drive/MyDrive/pp/pathway data set1111.csv\")"],"execution_count":531,"outputs":[]},{"cell_type":"code","metadata":{"id":"4MpKpxO_rNDN","executionInfo":{"status":"ok","timestamp":1656242788045,"user_tz":-330,"elapsed":17,"user":{"displayName":"Prudhvi Vuda","userId":"08510694787031450796"}}},"source":["df=df.drop([\"Unnamed: 11\"],axis=1)\n","df=df.drop([\"Unnamed: 12\"],axis=1)\n","df=df.drop([\"Unnamed: 13\"],axis=1)"],"execution_count":532,"outputs":[]},{"cell_type":"code","metadata":{"id":"gNjYSr9crayo","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ab0d6f2f-dea0-4468-e4c3-cf1855bb7f47","executionInfo":{"status":"ok","timestamp":1656242788046,"user_tz":-330,"elapsed":17,"user":{"displayName":"Prudhvi Vuda","userId":"08510694787031450796"}}},"source":["df.path[df.path ==\"AKT\"] =1\n","df.path[df.path ==\"FASL\"] =2\n","df.path[df.path ==\"MAPK\"] =3\n","df.path[df.path ==\"NOTCH\"] =4\n","df.path[df.path ==\"SHH\"]=5\n","df.path[df.path ==\"TNF\"] =6\n","df.path[df.path ==\"WNT\"] =7\n","df.path[df.path ==\"MTOR\"] =8\n","print(df)"],"execution_count":533,"outputs":[{"output_type":"stream","name":"stdout","text":["    path   c1   c2   c3   c4   c5    c6   c7   c8   c9 Outcome\n","0      1  5.5  1.5  1.5  1.5  2.5   1.5  3.5  1.5  1.5      no\n","1      1  5.5  4.5  4.5  5.5  7.5  10.5  3.5  2.5  1.5     yes\n","2      1  3.5  1.5  1.5  1.5  2.5   2.5  3.5  1.5  1.5      no\n","3      1  6.5  8.5  8.5  1.5  3.5   4.5  3.5  7.5  1.5     yes\n","4      1  4.5  1.5  1.5  3.5  2.5   1.5  3.5  1.5  1.5      no\n","..   ...  ...  ...  ...  ...  ...   ...  ...  ...  ...     ...\n","595    8  5.5  1.5  1.5  1.5  2.5   1.5  2.5  1.5  1.5     yes\n","596    8  4.5  1.5  2.5  1.5  2.5   1.5  2.5  1.5  1.5      no\n","597    8  5.5  1.5  3.5  1.5  2.5   1.5  3.5  1.5  1.5     yes\n","598    8  3.5  1.5  1.5  1.5  2.5   1.5  2.5  1.5  1.5      no\n","599    8  5.5  2.5  4.5  1.5  1.5   1.5  1.5  1.5  1.5     yes\n","\n","[600 rows x 11 columns]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \"\"\"Entry point for launching an IPython kernel.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  This is separate from the ipykernel package so we can avoid doing imports until\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  after removing the cwd from sys.path.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \"\"\"\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  import sys\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n"]}]},{"cell_type":"code","metadata":{"id":"Ly4Gq4jrrdyh","colab":{"base_uri":"https://localhost:8080/","height":602},"outputId":"775eb3e2-fcee-4542-a8e3-d68df40fff82","executionInfo":{"status":"ok","timestamp":1656242788046,"user_tz":-330,"elapsed":15,"user":{"displayName":"Prudhvi Vuda","userId":"08510694787031450796"}}},"source":["df.Outcome[df.Outcome==\"no\"] = 0\n","df.Outcome[df.Outcome ==\"yes\"] = 1\n","df"],"execution_count":534,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \"\"\"Entry point for launching an IPython kernel.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \n"]},{"output_type":"execute_result","data":{"text/plain":["    path   c1   c2   c3   c4   c5    c6   c7   c8   c9 Outcome\n","0      1  5.5  1.5  1.5  1.5  2.5   1.5  3.5  1.5  1.5       0\n","1      1  5.5  4.5  4.5  5.5  7.5  10.5  3.5  2.5  1.5       1\n","2      1  3.5  1.5  1.5  1.5  2.5   2.5  3.5  1.5  1.5       0\n","3      1  6.5  8.5  8.5  1.5  3.5   4.5  3.5  7.5  1.5       1\n","4      1  4.5  1.5  1.5  3.5  2.5   1.5  3.5  1.5  1.5       0\n","..   ...  ...  ...  ...  ...  ...   ...  ...  ...  ...     ...\n","595    8  5.5  1.5  1.5  1.5  2.5   1.5  2.5  1.5  1.5       1\n","596    8  4.5  1.5  2.5  1.5  2.5   1.5  2.5  1.5  1.5       0\n","597    8  5.5  1.5  3.5  1.5  2.5   1.5  3.5  1.5  1.5       1\n","598    8  3.5  1.5  1.5  1.5  2.5   1.5  2.5  1.5  1.5       0\n","599    8  5.5  2.5  4.5  1.5  1.5   1.5  1.5  1.5  1.5       1\n","\n","[600 rows x 11 columns]"],"text/html":["\n","  <div id=\"df-5fcc55d1-0f03-4b46-ae1b-6a0c3af3dde0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>path</th>\n","      <th>c1</th>\n","      <th>c2</th>\n","      <th>c3</th>\n","      <th>c4</th>\n","      <th>c5</th>\n","      <th>c6</th>\n","      <th>c7</th>\n","      <th>c8</th>\n","      <th>c9</th>\n","      <th>Outcome</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>5.5</td>\n","      <td>1.5</td>\n","      <td>1.5</td>\n","      <td>1.5</td>\n","      <td>2.5</td>\n","      <td>1.5</td>\n","      <td>3.5</td>\n","      <td>1.5</td>\n","      <td>1.5</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>5.5</td>\n","      <td>4.5</td>\n","      <td>4.5</td>\n","      <td>5.5</td>\n","      <td>7.5</td>\n","      <td>10.5</td>\n","      <td>3.5</td>\n","      <td>2.5</td>\n","      <td>1.5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>3.5</td>\n","      <td>1.5</td>\n","      <td>1.5</td>\n","      <td>1.5</td>\n","      <td>2.5</td>\n","      <td>2.5</td>\n","      <td>3.5</td>\n","      <td>1.5</td>\n","      <td>1.5</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>6.5</td>\n","      <td>8.5</td>\n","      <td>8.5</td>\n","      <td>1.5</td>\n","      <td>3.5</td>\n","      <td>4.5</td>\n","      <td>3.5</td>\n","      <td>7.5</td>\n","      <td>1.5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>4.5</td>\n","      <td>1.5</td>\n","      <td>1.5</td>\n","      <td>3.5</td>\n","      <td>2.5</td>\n","      <td>1.5</td>\n","      <td>3.5</td>\n","      <td>1.5</td>\n","      <td>1.5</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>595</th>\n","      <td>8</td>\n","      <td>5.5</td>\n","      <td>1.5</td>\n","      <td>1.5</td>\n","      <td>1.5</td>\n","      <td>2.5</td>\n","      <td>1.5</td>\n","      <td>2.5</td>\n","      <td>1.5</td>\n","      <td>1.5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>596</th>\n","      <td>8</td>\n","      <td>4.5</td>\n","      <td>1.5</td>\n","      <td>2.5</td>\n","      <td>1.5</td>\n","      <td>2.5</td>\n","      <td>1.5</td>\n","      <td>2.5</td>\n","      <td>1.5</td>\n","      <td>1.5</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>597</th>\n","      <td>8</td>\n","      <td>5.5</td>\n","      <td>1.5</td>\n","      <td>3.5</td>\n","      <td>1.5</td>\n","      <td>2.5</td>\n","      <td>1.5</td>\n","      <td>3.5</td>\n","      <td>1.5</td>\n","      <td>1.5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>598</th>\n","      <td>8</td>\n","      <td>3.5</td>\n","      <td>1.5</td>\n","      <td>1.5</td>\n","      <td>1.5</td>\n","      <td>2.5</td>\n","      <td>1.5</td>\n","      <td>2.5</td>\n","      <td>1.5</td>\n","      <td>1.5</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>599</th>\n","      <td>8</td>\n","      <td>5.5</td>\n","      <td>2.5</td>\n","      <td>4.5</td>\n","      <td>1.5</td>\n","      <td>1.5</td>\n","      <td>1.5</td>\n","      <td>1.5</td>\n","      <td>1.5</td>\n","      <td>1.5</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>600 rows × 11 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5fcc55d1-0f03-4b46-ae1b-6a0c3af3dde0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5fcc55d1-0f03-4b46-ae1b-6a0c3af3dde0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5fcc55d1-0f03-4b46-ae1b-6a0c3af3dde0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":534}]},{"cell_type":"code","metadata":{"id":"uuIHcHCprjSo","executionInfo":{"status":"ok","timestamp":1656242788046,"user_tz":-330,"elapsed":11,"user":{"displayName":"Prudhvi Vuda","userId":"08510694787031450796"}}},"source":["#Lets seperste Data\n","X=df.iloc[:,:10].values\n","Y=df.iloc[:,10].values\n","num_train=X.shape[0]\n","input_dim=X.shape[1]\n","Y.shape=(num_train,1)"],"execution_count":535,"outputs":[]},{"cell_type":"code","metadata":{"id":"CWMLEJNbsJV5","colab":{"base_uri":"https://localhost:8080/"},"outputId":"94f99ae3-9d03-4976-ce30-66db81e269cd","executionInfo":{"status":"ok","timestamp":1656242788047,"user_tz":-330,"elapsed":11,"user":{"displayName":"Prudhvi Vuda","userId":"08510694787031450796"}}},"source":["X=X.astype('int')\n","Y=Y.astype('int')\n","input_dim"],"execution_count":536,"outputs":[{"output_type":"execute_result","data":{"text/plain":["10"]},"metadata":{},"execution_count":536}]},{"cell_type":"code","metadata":{"id":"8fd_otaDsLqW","executionInfo":{"status":"ok","timestamp":1656242788047,"user_tz":-330,"elapsed":10,"user":{"displayName":"Prudhvi Vuda","userId":"08510694787031450796"}}},"source":["X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=42)"],"execution_count":537,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n","# from .optimizer import Optimizer\n","\n","\n","class Adam(keras.optimizers.Optimizer):\n","    r\"\"\"Implements Adam algorithm.\n","\n","    .. math::\n","       \\begin{aligned}\n","            &\\rule{110mm}{0.4pt}                                                                 \\\\\n","            &\\textbf{input}      : \\gamma \\text{ (lr)}, \\beta_1, \\beta_2\n","                \\text{ (betas)},\\theta_0 \\text{ (params)},f(\\theta) \\text{ (objective)}          \\\\\n","            &\\hspace{13mm}      \\lambda \\text{ (weight decay)},  \\: \\textit{amsgrad},\n","                \\:\\textit{maximize}                                                              \\\\\n","            &\\textbf{initialize} :  m_0 \\leftarrow 0 \\text{ ( first moment)},\n","                v_0\\leftarrow 0 \\text{ (second moment)},\\: \\widehat{v_0}^{max}\\leftarrow 0\\\\[-1.ex]\n","            &\\rule{110mm}{0.4pt}                                                                 \\\\\n","            &\\textbf{for} \\: t=1 \\: \\textbf{to} \\: \\ldots \\: \\textbf{do}                         \\\\\n","\n","            &\\hspace{5mm}\\textbf{if} \\: \\textit{maximize}:                                       \\\\\n","            &\\hspace{10mm}g_t           \\leftarrow   -\\nabla_{\\theta} f_t (\\theta_{t-1})         \\\\\n","            &\\hspace{5mm}\\textbf{else}                                                           \\\\\n","            &\\hspace{10mm}g_t           \\leftarrow   \\nabla_{\\theta} f_t (\\theta_{t-1})          \\\\\n","            &\\hspace{5mm}\\textbf{if} \\: \\lambda \\neq 0                                           \\\\\n","            &\\hspace{10mm} g_t \\leftarrow g_t + \\lambda  \\theta_{t-1}                            \\\\\n","            &\\hspace{5mm}m_t           \\leftarrow   \\beta_1 m_{t-1} + (1 - \\beta_1) g_t          \\\\\n","            &\\hspace{5mm}v_t           \\leftarrow   \\beta_2 v_{t-1} + (1-\\beta_2) g^2_t          \\\\\n","            &\\hspace{5mm}\\widehat{m_t} \\leftarrow   m_t/\\big(1-\\beta_1^t \\big)                   \\\\\n","            &\\hspace{5mm}\\widehat{v_t} \\leftarrow   v_t/\\big(1-\\beta_2^t \\big)                   \\\\\n","            &\\hspace{5mm}\\textbf{if} \\: amsgrad                                                  \\\\\n","            &\\hspace{10mm}\\widehat{v_t}^{max} \\leftarrow \\mathrm{max}(\\widehat{v_t}^{max},\n","                \\widehat{v_t})                                                                   \\\\\n","            &\\hspace{10mm}\\theta_t \\leftarrow \\theta_{t-1} - \\gamma \\widehat{m_t}/\n","                \\big(\\sqrt{\\widehat{v_t}^{max}} + \\epsilon \\big)                                 \\\\\n","            &\\hspace{5mm}\\textbf{else}                                                           \\\\\n","            &\\hspace{10mm}\\theta_t \\leftarrow \\theta_{t-1} - \\gamma \\widehat{m_t}/\n","                \\big(\\sqrt{\\widehat{v_t}} + \\epsilon \\big)                                       \\\\\n","            &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n","            &\\bf{return} \\:  \\theta_t                                                     \\\\[-1.ex]\n","            &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n","       \\end{aligned}\n","\n","    For further details regarding the algorithm we refer to `Adam: A Method for Stochastic Optimization`_.\n","\n","    Args:\n","        params (iterable): iterable of parameters to optimize or dicts defining\n","            parameter groups\n","        lr (float, optional): learning rate (default: 1e-3)\n","        betas (Tuple[float, float], optional): coefficients used for computing\n","            running averages of gradient and its square (default: (0.9, 0.999))\n","        eps (float, optional): term added to the denominator to improve\n","            numerical stability (default: 1e-8)\n","        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n","        amsgrad (boolean, optional): whether to use the AMSGrad variant of this\n","            algorithm from the paper `On the Convergence of Adam and Beyond`_\n","            (default: False)\n","        maximize (bool, optional): maximize the params based on the objective, instead of\n","            minimizing (default: False)\n","\n","    .. _Adam\\: A Method for Stochastic Optimization:\n","        https://arxiv.org/abs/1412.6980\n","    .. _On the Convergence of Adam and Beyond:\n","        https://openreview.net/forum?id=ryQu7f-RZ\n","    \"\"\"\n","\n","    def __init__(self,lr=1e-3, betas=(0.9, 0.999), eps=1e-10,\n","                 weight_decay=0, amsgrad=False, *, maximize: bool = False):\n","        defaults = dict(lr=lr, betas=betas, eps=eps,\n","                        weight_decay=weight_decay, amsgrad=amsgrad, maximize=maximize)\n","        super(Adam, self).__init__(params, defaults)\n","\n","    def __setstate__(self, state):\n","        super(Adam, self).__setstate__(state)\n","        for group in self.param_groups:\n","            group.setdefault('amsgrad', False)\n","            group.setdefault('maximize', False)\n","\n","    @torch.no_grad()\n","    def step(self, closure=None):\n","        loss = None\n","        if closure is not None:\n","            with torch.enable_grad():\n","                loss = closure()\n","\n","        for group in self.param_groups:\n","            params_with_grad = []\n","            grads = []\n","            exp_avgs = []\n","            exp_avg_sqs = []\n","            max_exp_avg_sqs = []\n","            state_steps = []\n","            beta1, beta2 = group['betas']\n","\n","            for p in group['params']:\n","                if p.grad is not None:\n","                    params_with_grad.append(p)\n","                    if p.grad.is_sparse:\n","                        raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n","                    grads.append(p.grad)\n","\n","                    state = self.state[p]\n","                    # Lazy state initialization\n","                    if len(state) == 0:\n","                        state['step'] = 0\n","                        # Exponential moving average of gradient values\n","                        state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n","                        # Exponential moving average of squared gradient values\n","                        state['exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n","                        if group['amsgrad']:\n","                            # Maintains max of all exp. moving avg. of sq. grad. values\n","                            state['max_exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n","\n","                    exp_avgs.append(state['exp_avg'])\n","                    exp_avg_sqs.append(state['exp_avg_sq'])\n","\n","                    if group['amsgrad']:\n","                        max_exp_avg_sqs.append(state['max_exp_avg_sq'])\n","\n","                    # update the steps for each param group update\n","                    state['step'] += 1\n","                    # record the step after step update\n","                    state_steps.append(state['step'])\n","\n","            F.adam(params_with_grad,\n","                   grads,\n","                   exp_avgs,\n","                   exp_avg_sqs,\n","                   max_exp_avg_sqs,\n","                   state_steps,\n","                   amsgrad=group['amsgrad'],\n","                   beta1=beta1,\n","                   beta2=beta2,\n","                   lr=group['lr'],\n","                   weight_decay=group['weight_decay'],\n","                   eps=group['eps'],\n","                   maximize=group['maximize'])\n","        return loss"],"metadata":{"id":"F-r0VZpN8sjv","executionInfo":{"status":"ok","timestamp":1656242788047,"user_tz":-330,"elapsed":10,"user":{"displayName":"Prudhvi Vuda","userId":"08510694787031450796"}}},"execution_count":538,"outputs":[]},{"cell_type":"code","metadata":{"id":"S-gw3r35sP1J","executionInfo":{"status":"ok","timestamp":1656242788621,"user_tz":-330,"elapsed":583,"user":{"displayName":"Prudhvi Vuda","userId":"08510694787031450796"}}},"source":["#LAyers and Neurons\n","model = Sequential()\n","#first Layer\n","model.add(Dense(12,input_dim=10,activation='relu'))\n","#Second LAyer\n","model.add(Dense(8,activation='relu'))\n","#third LAyer\n","model.add(Dense(10,activation='relu'))\n","#Output\n","model.add(Dense(1,activation='sigmoid'))"],"execution_count":539,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gg-99KibslNL","executionInfo":{"status":"ok","timestamp":1656242788621,"user_tz":-330,"elapsed":8,"user":{"displayName":"Prudhvi Vuda","userId":"08510694787031450796"}}},"source":["opt = tf.keras.optimizers.Adam(learning_rate=0.001,beta_1=0.99,beta_2=0.999,epsilon=1e-10,amsgrad=False, name='Adam')\n","\n","model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"],"execution_count":540,"outputs":[]},{"cell_type":"code","metadata":{"id":"vKkNWqvBsnso","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6d2ebf20-39ff-41d5-9139-48b9d4be7e45","executionInfo":{"status":"ok","timestamp":1656242794022,"user_tz":-330,"elapsed":5408,"user":{"displayName":"Prudhvi Vuda","userId":"08510694787031450796"}}},"source":["model.fit(X_train,Y_train,batch_size=32,epochs=100,verbose=1)"],"execution_count":541,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.8597 - accuracy: 0.5021\n","Epoch 2/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.6994 - accuracy: 0.6021\n","Epoch 3/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.6241 - accuracy: 0.7542\n","Epoch 4/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.5911 - accuracy: 0.7312\n","Epoch 5/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.5722 - accuracy: 0.7000\n","Epoch 6/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.5476 - accuracy: 0.7125\n","Epoch 7/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7375\n","Epoch 8/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7917\n","Epoch 9/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.8313\n","Epoch 10/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.4048 - accuracy: 0.8417\n","Epoch 11/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3855 - accuracy: 0.8417\n","Epoch 12/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3758 - accuracy: 0.8396\n","Epoch 13/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3599 - accuracy: 0.8396\n","Epoch 14/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3440 - accuracy: 0.8438\n","Epoch 15/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3345 - accuracy: 0.8438\n","Epoch 16/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3254 - accuracy: 0.8583\n","Epoch 17/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8583\n","Epoch 18/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3201 - accuracy: 0.8479\n","Epoch 19/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3165 - accuracy: 0.8562\n","Epoch 20/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.8583\n","Epoch 21/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3055 - accuracy: 0.8625\n","Epoch 22/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.3018 - accuracy: 0.8667\n","Epoch 23/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2978 - accuracy: 0.8646\n","Epoch 24/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2922 - accuracy: 0.8625\n","Epoch 25/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2842 - accuracy: 0.8667\n","Epoch 26/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2781 - accuracy: 0.8729\n","Epoch 27/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2714 - accuracy: 0.8729\n","Epoch 28/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2658 - accuracy: 0.8708\n","Epoch 29/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2603 - accuracy: 0.8854\n","Epoch 30/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2536 - accuracy: 0.8875\n","Epoch 31/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2486 - accuracy: 0.8938\n","Epoch 32/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.8958\n","Epoch 33/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2407 - accuracy: 0.8979\n","Epoch 34/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2371 - accuracy: 0.8979\n","Epoch 35/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2334 - accuracy: 0.9021\n","Epoch 36/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2294 - accuracy: 0.9000\n","Epoch 37/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2261 - accuracy: 0.9021\n","Epoch 38/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2226 - accuracy: 0.9021\n","Epoch 39/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2193 - accuracy: 0.9021\n","Epoch 40/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2168 - accuracy: 0.9104\n","Epoch 41/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2143 - accuracy: 0.9104\n","Epoch 42/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2119 - accuracy: 0.9125\n","Epoch 43/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2091 - accuracy: 0.9125\n","Epoch 44/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2071 - accuracy: 0.9125\n","Epoch 45/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2047 - accuracy: 0.9146\n","Epoch 46/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2026 - accuracy: 0.9208\n","Epoch 47/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.2004 - accuracy: 0.9187\n","Epoch 48/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1982 - accuracy: 0.9187\n","Epoch 49/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1963 - accuracy: 0.9208\n","Epoch 50/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1941 - accuracy: 0.9208\n","Epoch 51/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1917 - accuracy: 0.9229\n","Epoch 52/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1896 - accuracy: 0.9229\n","Epoch 53/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1877 - accuracy: 0.9250\n","Epoch 54/100\n","15/15 [==============================] - 0s 3ms/step - loss: 0.1860 - accuracy: 0.9250\n","Epoch 55/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1842 - accuracy: 0.9250\n","Epoch 56/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1823 - accuracy: 0.9250\n","Epoch 57/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1806 - accuracy: 0.9271\n","Epoch 58/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1788 - accuracy: 0.9271\n","Epoch 59/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1769 - accuracy: 0.9271\n","Epoch 60/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1755 - accuracy: 0.9292\n","Epoch 61/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1735 - accuracy: 0.9312\n","Epoch 62/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1718 - accuracy: 0.9333\n","Epoch 63/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1703 - accuracy: 0.9354\n","Epoch 64/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1690 - accuracy: 0.9354\n","Epoch 65/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1674 - accuracy: 0.9354\n","Epoch 66/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1657 - accuracy: 0.9375\n","Epoch 67/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1643 - accuracy: 0.9375\n","Epoch 68/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1629 - accuracy: 0.9375\n","Epoch 69/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1612 - accuracy: 0.9375\n","Epoch 70/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1597 - accuracy: 0.9375\n","Epoch 71/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1585 - accuracy: 0.9417\n","Epoch 72/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1568 - accuracy: 0.9417\n","Epoch 73/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1552 - accuracy: 0.9438\n","Epoch 74/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1539 - accuracy: 0.9438\n","Epoch 75/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1524 - accuracy: 0.9438\n","Epoch 76/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1512 - accuracy: 0.9458\n","Epoch 77/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1497 - accuracy: 0.9479\n","Epoch 78/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1482 - accuracy: 0.9521\n","Epoch 79/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1469 - accuracy: 0.9500\n","Epoch 80/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1454 - accuracy: 0.9521\n","Epoch 81/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1444 - accuracy: 0.9563\n","Epoch 82/100\n","15/15 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9583\n","Epoch 83/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1417 - accuracy: 0.9604\n","Epoch 84/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1404 - accuracy: 0.9604\n","Epoch 85/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1399 - accuracy: 0.9604\n","Epoch 86/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1378 - accuracy: 0.9604\n","Epoch 87/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1364 - accuracy: 0.9604\n","Epoch 88/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1355 - accuracy: 0.9625\n","Epoch 89/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1346 - accuracy: 0.9625\n","Epoch 90/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1333 - accuracy: 0.9625\n","Epoch 91/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1320 - accuracy: 0.9646\n","Epoch 92/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1310 - accuracy: 0.9646\n","Epoch 93/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1298 - accuracy: 0.9646\n","Epoch 94/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1290 - accuracy: 0.9646\n","Epoch 95/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1271 - accuracy: 0.9646\n","Epoch 96/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1257 - accuracy: 0.9646\n","Epoch 97/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1243 - accuracy: 0.9646\n","Epoch 98/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1236 - accuracy: 0.9625\n","Epoch 99/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1219 - accuracy: 0.9646\n","Epoch 100/100\n","15/15 [==============================] - 0s 2ms/step - loss: 0.1209 - accuracy: 0.9688\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f57ecd46550>"]},"metadata":{},"execution_count":541}]},{"cell_type":"code","metadata":{"id":"nNjHFA73sq0_","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9cd0ef9f-48ad-4f44-d89e-38f32b6b75da","executionInfo":{"status":"ok","timestamp":1656242794022,"user_tz":-330,"elapsed":19,"user":{"displayName":"Prudhvi Vuda","userId":"08510694787031450796"}}},"source":["scores = model.evaluate(X_test, Y_test, batch_size=32, verbose=1)\n","print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"],"execution_count":542,"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 0s 3ms/step - loss: 0.3217 - accuracy: 0.9083\n","\n","accuracy: 90.83%\n"]}]},{"cell_type":"code","metadata":{"id":"eo541e-ptN8p","colab":{"base_uri":"https://localhost:8080/"},"outputId":"bac563ff-a856-4e47-cdef-2cc547f9a558","executionInfo":{"status":"ok","timestamp":1656242794022,"user_tz":-330,"elapsed":16,"user":{"displayName":"Prudhvi Vuda","userId":"08510694787031450796"}}},"source":["prediction=model.predict(np.array([[1,6.5,8.5,8.5,1.5,3.5,4.5,3.5,7.5,1.5]]))\n","if (prediction<=0.5):print(\"NO\")\n","elif (prediction>0.5):print(\"Yes\")"],"execution_count":543,"outputs":[{"output_type":"stream","name":"stdout","text":["Yes\n"]}]},{"cell_type":"code","metadata":{"id":"d7nZBcEStRQx","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3c804171-604e-41a4-8014-293a0dce6a01","executionInfo":{"status":"ok","timestamp":1656242794023,"user_tz":-330,"elapsed":15,"user":{"displayName":"Prudhvi Vuda","userId":"08510694787031450796"}}},"source":["prediction=model.predict(np.array([[8,4.5,1.5,2.5,1.5,2.5,1.5,2.5,1.5,1.5]]))\n","#labels=np.argmax(prediction,axis=-1)\n","labels=(prediction>0.5).astype(int)\n","if (labels==1):print(\"Yes\")\n","elif (labels==0):print(\"No\")"],"execution_count":544,"outputs":[{"output_type":"stream","name":"stdout","text":["No\n"]}]}]}